{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ffd954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random, numpy as np\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "print(f\"Global seed set to {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d39acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/ayannareda/Weather-Detection-Using-Images.git\n",
    "# url - /kaggle/working/Weather-Detection-Using-Images/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fce2053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class ImageFilenameDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.files = []\n",
    "        for label_name in os.listdir(root):\n",
    "            label_dir = os.path.join(root, label_name)\n",
    "            if os.path.isdir(label_dir) and label_name.isdigit():\n",
    "                for fname in sorted(os.listdir(label_dir)):\n",
    "                    if fname.lower().endswith(('.jpg', '.png')):\n",
    "                        path = os.path.join(label_dir, fname)\n",
    "                        self.files.append((path, int(label_name)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.files[idx]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecbf884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StarGAN Generator with ResNet blocks\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(dim, dim, 3, 1, 1), nn.InstanceNorm2d(dim), nn.ReLU(),\n",
    "            nn.Conv2d(dim, dim, 3, 1, 1), nn.InstanceNorm2d(dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_ch=3, n_classes=5, n_blocks=6):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "        # initial conv\n",
    "        model = [nn.Conv2d(in_ch + n_classes, 64, 7, 1, 3), nn.InstanceNorm2d(64), nn.ReLU()]\n",
    "        # downsample\n",
    "        dim = 64\n",
    "        for _ in range(2):\n",
    "            model += [nn.Conv2d(dim, dim*2, 4, 2, 1), nn.InstanceNorm2d(dim*2), nn.ReLU()]\n",
    "            dim *= 2\n",
    "        # ResNet blocks\n",
    "        for _ in range(n_blocks):\n",
    "            model += [ResnetBlock(dim)]\n",
    "        # upsample\n",
    "        for _ in range(2):\n",
    "            model += [nn.ConvTranspose2d(dim, dim//2, 4, 2, 1), nn.InstanceNorm2d(dim//2), nn.ReLU()]\n",
    "            dim //= 2\n",
    "        # final conv\n",
    "        model += [nn.Conv2d(dim, in_ch, 7, 1, 3), nn.Tanh()]\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x, target_label):\n",
    "        # target_label: one-hot tensor of shape (B, n_classes)\n",
    "        b, _, h, w = x.size()\n",
    "        label_map = target_label.view(b, self.n_classes, 1, 1).expand(b, self.n_classes, h, w)\n",
    "        inp = torch.cat([x, label_map], dim=1) # [B, in_ch + n_classes, h, w]\n",
    "        return self.model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e205b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StarGAN Discriminator with adversarial and classification heads\n",
    "import torch.nn as nn\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_ch=3, n_classes=5):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        dim = in_ch\n",
    "        for out_dim in [64, 128, 256, 512]:\n",
    "            layers += [nn.Conv2d(dim, out_dim, 4, 2, 1), nn.LeakyReLU(0.01)]\n",
    "            dim = out_dim\n",
    "        self.main = nn.Sequential(*layers)\n",
    "        self.adv_head = nn.Conv2d(512, 1, 3, 1, 1)\n",
    "        self.cls_head = nn.Conv2d(512, n_classes, 3, 1, 1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h       = self.main(x)           # [B,512,H',W']\n",
    "        out_adv = self.adv_head(h)       # [B,1, H',W']\n",
    "        out_cls = self.cls_head(h)       # [B,n_classes,H',W']\n",
    "        out_cls = self.global_pool(out_cls)  # [B,n_classes,1,1]\n",
    "        out_cls = out_cls.view(h.size(0), -1)  # [B,n_classes]\n",
    "        return out_adv, out_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def train(G, D, train_loader, val_loader, optim_G, optim_D, device,\n",
    "          epochs=50, lambda_cls=1.0, lambda_rec=10.0,\n",
    "          checkpoint_dir='checkpoints', resume_path=None):\n",
    "    # initialize metrics storage\n",
    "    metrics = {\n",
    "        'train_adv': [], 'train_cls': [], 'train_rec': [],\n",
    "        'val_adv':   [], 'val_cls':   [], 'val_rec':   []\n",
    "    }\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    start_epoch = 1\n",
    "    # -- resume if provided --\n",
    "    if resume_path and os.path.exists(resume_path):\n",
    "        ckpt = torch.load(resume_path, map_location=device)\n",
    "        G.load_state_dict(ckpt['G_state']); D.load_state_dict(ckpt['D_state'])\n",
    "        optim_G.load_state_dict(ckpt['optim_G_state'])\n",
    "        optim_D.load_state_dict(ckpt['optim_D_state'])\n",
    "        start_epoch = ckpt.get('epoch', 1) + 1\n",
    "        print(f\"Resuming from epoch {start_epoch}\")\n",
    "\n",
    "    adv_criterion = torch.nn.MSELoss()\n",
    "    cls_criterion = torch.nn.CrossEntropyLoss()\n",
    "    rec_criterion = torch.nn.L1Loss()\n",
    "    G.to(device); D.to(device)\n",
    "\n",
    "    for epoch in range(start_epoch, epochs+1):\n",
    "        G.train(); D.train()\n",
    "        train_stats = {'adv': [], 'cls': [], 'rec': []}\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs} [Train]\")\n",
    "        for real_x, real_lbl in pbar:\n",
    "            real_x, real_lbl = real_x.to(device), real_lbl.to(device)\n",
    "            B = real_x.size(0)\n",
    "            idx = torch.randperm(B); target_lbl = real_lbl[idx]\n",
    "            target_oh = F.one_hot(target_lbl, G.module.n_classes if isinstance(G, torch.nn.DataParallel) else G.n_classes).float().to(device)\n",
    "\n",
    "            # Discriminator\n",
    "            fake_x = G(real_x, target_oh).detach()\n",
    "            optim_D.zero_grad()\n",
    "            real_adv, real_cls = D(real_x)\n",
    "            fake_adv, _ = D(fake_x)\n",
    "            loss_D = adv_criterion(real_adv, torch.ones_like(real_adv)) + \\\n",
    "                     adv_criterion(fake_adv, torch.zeros_like(fake_adv)) + \\\n",
    "                     lambda_cls * cls_criterion(real_cls, real_lbl)\n",
    "            loss_D.backward(); optim_D.step()\n",
    "            \n",
    "            # Generator\n",
    "            optim_G.zero_grad()\n",
    "            fake_x = G(real_x, target_oh)\n",
    "            adv_out, cls_out = D(fake_x)\n",
    "            rec_lbl_oh = F.one_hot(real_lbl, G.module.n_classes if isinstance(G, torch.nn.DataParallel) else G.n_classes).float().to(device)\n",
    "            rec_x = G(fake_x, rec_lbl_oh)\n",
    "            loss_G = adv_criterion(adv_out, torch.ones_like(adv_out)) + \\\n",
    "                     lambda_cls * cls_criterion(cls_out, target_lbl) + \\\n",
    "                     lambda_rec * rec_criterion(rec_x, real_x)\n",
    "            loss_G.backward(); optim_G.step()\n",
    "\n",
    "            # collect stats\n",
    "            train_stats['adv'].append(loss_G.item())\n",
    "            train_stats['cls'].append(cls_criterion(cls_out, target_lbl).item())\n",
    "            train_stats['rec'].append(rec_criterion(rec_x, real_x).item())\n",
    "            pbar.set_postfix({k: np.mean(v) for k, v in train_stats.items()})\n",
    "\n",
    "        # Validation\n",
    "        G.eval(); D.eval()\n",
    "        val_stats = {'adv': [], 'cls': [], 'rec': []}\n",
    "        with torch.no_grad():\n",
    "            vbar = tqdm(val_loader, desc=f\"Epoch {epoch}/{epochs} [Val]\")\n",
    "            for real_x, real_lbl in vbar:\n",
    "                real_x, real_lbl = real_x.to(device), real_lbl.to(device)\n",
    "                B = real_x.size(0)\n",
    "                idx = torch.randperm(B); target_lbl = real_lbl[idx]\n",
    "                target_oh = F.one_hot(target_lbl, G.module.n_classes if isinstance(G, torch.nn.DataParallel) else G.n_classes).float().to(device)\n",
    "                fake_x = G(real_x, target_oh)\n",
    "                adv_out, cls_out = D(fake_x)\n",
    "                rec_lbl_oh = F.one_hot(real_lbl, G.module.n_classes if isinstance(G, torch.nn.DataParallel) else G.n_classes).float().to(device)\n",
    "                rec_x = G(fake_x, rec_lbl_oh)\n",
    "                val_stats['adv'].append(adv_criterion(adv_out, torch.ones_like(adv_out)).item())\n",
    "                val_stats['cls'].append(cls_criterion(cls_out, target_lbl).item())\n",
    "                val_stats['rec'].append(rec_criterion(rec_x, real_x).item())\n",
    "                vbar.set_postfix({k: np.mean(v) for k, v in val_stats.items()})\n",
    "\n",
    "        # Log metrics\n",
    "        print(f\"Epoch {epoch}: Train -> adv={np.mean(train_stats['adv']):.4f}, \",\n",
    "              f\"cls={np.mean(train_stats['cls']):.4f}, rec={np.mean(train_stats['rec']):.4f}\")\n",
    "        print(f\"           Val   -> adv={np.mean(val_stats['adv']):.4f}, \",\n",
    "              f\"cls={np.mean(val_stats['cls']):.4f}, rec={np.mean(val_stats['rec']):.4f}\")\n",
    "\n",
    "        # Save checkpoint\n",
    "        if epoch % 2 == 0 or epoch == epochs:\n",
    "            ckpt_path = os.path.join(checkpoint_dir, f\"ckpt_epoch_{epoch}.pt\")\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'G_state': G.state_dict(),\n",
    "                'D_state': D.state_dict(),\n",
    "                'optim_G_state': optim_G.state_dict(),\n",
    "                'optim_D_state': optim_D.state_dict()\n",
    "            }, ckpt_path)\n",
    "        # append epoch metrics\n",
    "        metrics['train_adv'].append(np.mean(train_stats['adv']))\n",
    "        metrics['train_cls'].append(np.mean(train_stats['cls']))\n",
    "        metrics['train_rec'].append(np.mean(train_stats['rec']))\n",
    "        metrics['val_adv'].append(np.mean(val_stats['adv']))\n",
    "        metrics['val_cls'].append(np.mean(val_stats['cls']))\n",
    "        metrics['val_rec'].append(np.mean(val_stats['rec']))\n",
    "    # end epochs\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e86ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# Example usage of train_starGAN function\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Instantiate models\n",
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    G = nn.DataParallel(G)\n",
    "    D = nn.DataParallel(D)\n",
    "\n",
    "# Optimizers\n",
    "optim_G = torch.optim.Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "optim_D = torch.optim.Adam(D.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "\n",
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "# Create dataset and split into train and validation sets\n",
    "BATCH_SIZE = 48\n",
    "dataset = ImageFilenameDataset('/kaggle/working/Weather-Detection-Using-Images/Data', transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "# Call train_starGAN function\n",
    "metrics = train(\n",
    "    G, D,\n",
    "    train_loader, val_loader,\n",
    "    optim_G, optim_D,\n",
    "    device,\n",
    "    epochs=20,\n",
    "    checkpoint_dir='checkpoints'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ca86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf2a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference cell\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.nn import DataParallel\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 1) define transforms (must match training)\n",
    "transform_in = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "# 2) helper to undo Normalize\n",
    "unnormalize = transforms.Normalize(\n",
    "    mean=[-1.0, -1.0, -1.0],\n",
    "    std =[2.0,  2.0,  2.0]\n",
    ")\n",
    "\n",
    "# 3) load checkpoint & build model\n",
    "ckpt = torch.load('ckpt_epoch_3.pt', map_location=device)\n",
    "# If model was trained with DataParallel, wrap before loading state dict\n",
    "\n",
    "G = Generator().to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    G = nn.DataParallel(G)\n",
    "G.load_state_dict(ckpt['G_state'])\n",
    "G.eval()\n",
    "\n",
    "# 4) inference function\n",
    "def infer(img_path, target_label):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    x   = transform_in(img).unsqueeze(0).to(device)\n",
    "    lbl = torch.tensor([target_label], device=device)\n",
    "    with torch.no_grad():\n",
    "        fake = G(x, target_label=F.one_hot(lbl, num_classes=G.n_classes).float().to(device))\n",
    "    # undo normalization & clamp\n",
    "    fake = unnormalize(fake.squeeze(0).cpu()).clamp(0,1)\n",
    "    return img, transforms.ToPILImage()(fake)\n",
    "\n",
    "# 5) run on an example\n",
    "base_path = '/kaggle/working/Weather-Detection-Using-Images/Data'\n",
    "img_path = os.path.join(base_path, '1', '2256833238.jpg')\n",
    "\n",
    "original, generated = infer(img_path, target_label=2)    # choose your label index\n",
    "\n",
    "# Display side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(original); axes[0].axis('off'); axes[0].set_title('Original Image')\n",
    "axes[1].imshow(generated); axes[1].axis('off'); axes[1].set_title('Generated Image')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
